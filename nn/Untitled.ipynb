{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f437af1b-18fd-4b7e-ba81-f969a0b23268",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import torch\n",
    "import torchvision ## Contains some utilities for working with the image data\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "662e357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetFromDepthImages(Dataset):\n",
    "    def __init__(self, csv_path, img_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        # First column contains the image paths\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[1:, 0])\n",
    "        # Second column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[1:, 1])\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.data_info.index) - 2 \n",
    "\n",
    "        self.img_path = img_path\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = self.img_path + '/' + self.image_arr[index]\n",
    "        # Open image\n",
    "        img_as_img = np.load(single_image_name)\n",
    "        goal_np = img_as_img[:2]\n",
    "        goal_np /= 1000.0\n",
    "        img_as_img = img_as_img[2:]\n",
    "        img_as_img /= 10000.0\n",
    "        # Transform image to tensor\n",
    "        img_as_tensor = torch.from_numpy(img_as_img.astype('float32'))\n",
    "        img_as_tensor = torch.unsqueeze(img_as_tensor, 0)\n",
    "        img_as_tensor = torch.cat(tuple([img_as_tensor for item in range(len(img_as_img))]), 0)\n",
    "        img_as_tensor = torch.unsqueeze(img_as_tensor, 0)\n",
    "        \n",
    "        \n",
    "        goal_as_tensor = torch.from_numpy(goal_np.astype('float32'))\n",
    "        goal_as_tensor = torch.unsqueeze(goal_as_tensor, 1)\n",
    "        goal_as_tensor = torch.unsqueeze(goal_as_tensor, 1)\n",
    "\n",
    "\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.label_arr[index]\n",
    "\n",
    "        return (img_as_tensor, goal_as_tensor, int(single_image_label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ebb6d649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>File Name</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15932</th>\n",
       "      <td>15933.npy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15933</th>\n",
       "      <td>15934.npy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15934</th>\n",
       "      <td>15935.npy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15935</th>\n",
       "      <td>15936.npy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15936</th>\n",
       "      <td>15937.npy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15937 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1\n",
       "0      File Name  Label\n",
       "1          1.npy      1\n",
       "2          2.npy      1\n",
       "3          3.npy      1\n",
       "4          4.npy      1\n",
       "...          ...    ...\n",
       "15932  15933.npy      4\n",
       "15933  15934.npy      4\n",
       "15934  15935.npy      4\n",
       "15935  15936.npy      4\n",
       "15936  15937.npy      4\n",
       "\n",
       "[15937 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAPATH = '/home/alex/Documents/datasets/VisualPlanerData/iter_3/out.csv'\n",
    "DATAPATHIMAGES = '/home/alex/Documents/datasets/VisualPlanerData/iter_3'\n",
    "custom_dataset =  CustomDatasetFromDepthImages(DATAPATH, DATAPATHIMAGES)\n",
    "custom_dataset.data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbb0a6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]), tensor([[[ 0.4561]],\n",
      "\n",
      "        [[-0.4178]]]), 1)\n"
     ]
    }
   ],
   "source": [
    "print(custom_dataset[0])\n",
    "# plt.imshow(image, cmap = 'gray')\n",
    "# print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69cc6477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([-100, 100])\n",
    "t = torch.unsqueeze(t, 1)\n",
    "t = torch.unsqueeze(t, 1)\n",
    "t = torch.unsqueeze(t, 0)\n",
    "# t[0][0][0][0]\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "741a78ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40, 40]) torch.Size([2, 1, 1]) 1\n",
      "torch.Size([1, 40, 40])\n",
      "torch.Size([60, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_tensor, goal_tensor, label = custom_dataset[0]\n",
    "print(image_tensor.shape, goal_tensor.shape, label)\n",
    "print(image_tensor.shape)\n",
    "m = nn.Conv2d(1, 60, 3, stride=1, padding=1)\n",
    "# input = torch.randn(20, 16, 50)\n",
    "output = m(image_tensor)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa8ca06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.0690, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]])\n",
      "tensor(1.) tensor(0.0417)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(image_tensor)\n",
    "print(torch.max(image_tensor), torch.min(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb91f2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Train Datasets:  12748\n",
      "length of Validation Datasets:  3187\n"
     ]
    }
   ],
   "source": [
    "k = 0.8\n",
    "train_data_len = round(custom_dataset.data_len * k)\n",
    "validation_data_len = round(custom_dataset.data_len * (1-k))\n",
    "train_data, validation_data = random_split(custom_dataset, [train_data_len, validation_data_len])\n",
    "## Print the length of train and validation datasets\n",
    "print(\"length of Train Datasets: \", len(train_data))\n",
    "print(\"length of Validation Datasets: \", len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae595554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 40, 40])\n",
      "torch.Size([16, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(validation_data, batch_size, shuffle = False)\n",
    "\n",
    "for img, goal, label in train_loader:\n",
    "    print(img.shape)\n",
    "    print(goal.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82dd8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim = 1)\n",
    "    return(torch.tensor(torch.sum(preds == labels).item()/ len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a56e60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (conv0): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1): Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=82, out_features=150, bias=True)\n",
       "  (linear2): Linear(in_features=150, out_features=100, bias=True)\n",
       "  (linear3): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (linear4): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (linear5): Linear(in_features=25, out_features=6, bias=True)\n",
       "  (act): LeakyReLU(negative_slope=0.2)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (adaptivepool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 42*42\n",
    "num_classes = 6\n",
    "\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.conv0 = nn.Conv2d(1, 20, 3, stride=1, padding=1)\n",
    "        self.conv1 = nn.Conv2d(20, 40, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(40, 80, 3, stride=1, padding=1)\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(82, 150)\n",
    "        self.linear2 = nn.Linear(150, 100)\n",
    "        self.linear3 = nn.Linear(100, 50)\n",
    "        self.linear4 = nn.Linear(50, 25)\n",
    "        self.linear5 = nn.Linear(25, num_classes)\n",
    "\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1,1))\n",
    "    \n",
    "    def forward(self, x, g):\n",
    "        # print(xb.shape)\n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        # print(out.shape)\n",
    "        out = self.conv1(out)\n",
    "        out = self.act(out)\n",
    "        # print(out.shape)\n",
    "        out = self.conv2(out)\n",
    "        out = self.act(out)\n",
    "        # print(out.shape)\n",
    "\n",
    "        out = self.adaptivepool(out)\n",
    "        # print(out.shape)\n",
    "        out = torch.cat((out, g), 1)\n",
    "        # print(out.shape)\n",
    "\n",
    "        out = self.flat(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.act(out)\n",
    "        out = self.linear4(out)\n",
    "        out = self.act(out)\n",
    "        out = self.linear5(out)\n",
    "        return(out)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, goals, labels = batch\n",
    "        out = self(images, goals) ## Generate predictions\n",
    "        loss = self.loss_fn(out, labels) ## Calculate the loss\n",
    "        return(loss)\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, goals, labels = batch\n",
    "        out = self(images, goals)\n",
    "        # labels = F.one_hot(labels, num_classes)\n",
    "        # out = torch.argmax(out, dim=1) \n",
    "        # out = torch.argmax(out, dim=1) \n",
    "        # print(out.shape, labels.shape)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return({'val_loss':loss, 'val_acc': acc})\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return({'val_loss': epoch_loss.item(), 'val_acc' : epoch_acc.item()})\n",
    "    \n",
    "    def epoch_end(self, epoch,result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "    \n",
    "model = MnistModel()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62ac7ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6179]],\n",
      "\n",
      "        [[ 0.1903]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_tensor = custom_dataset[100][0]\n",
    "goal_tensor = custom_dataset[100][1]\n",
    "print(goal_tensor)\n",
    "image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "goal_tensor = torch.unsqueeze(goal_tensor, 0)\n",
    "model.forward(image_tensor, goal_tensor).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "017dbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return(model.validation_epoch_end(outputs))\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.Adam):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        ## Training Phas\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        ## Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c772649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 1.8897535800933838, 'val_acc': 0.14677418768405914}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2cdd952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.9122, val_acc: 0.6597\n",
      "Epoch [1], val_loss: 0.8163, val_acc: 0.6880\n",
      "Epoch [2], val_loss: 0.7938, val_acc: 0.6859\n",
      "Epoch [3], val_loss: 0.7816, val_acc: 0.6933\n",
      "Epoch [4], val_loss: 0.7554, val_acc: 0.7017\n",
      "Epoch [5], val_loss: 0.7310, val_acc: 0.7198\n",
      "Epoch [6], val_loss: 0.7562, val_acc: 0.7061\n",
      "Epoch [7], val_loss: 0.7122, val_acc: 0.7234\n",
      "Epoch [8], val_loss: 0.7296, val_acc: 0.7166\n",
      "Epoch [9], val_loss: 0.7023, val_acc: 0.7267\n",
      "Epoch [10], val_loss: 0.6857, val_acc: 0.7347\n",
      "Epoch [11], val_loss: 0.6778, val_acc: 0.7300\n",
      "Epoch [12], val_loss: 0.6685, val_acc: 0.7359\n",
      "Epoch [13], val_loss: 0.6592, val_acc: 0.7405\n",
      "Epoch [14], val_loss: 0.6730, val_acc: 0.7328\n",
      "Epoch [15], val_loss: 0.6771, val_acc: 0.7283\n",
      "Epoch [16], val_loss: 0.6169, val_acc: 0.7719\n",
      "Epoch [17], val_loss: 0.6200, val_acc: 0.7682\n",
      "Epoch [18], val_loss: 0.6509, val_acc: 0.7434\n",
      "Epoch [19], val_loss: 0.6105, val_acc: 0.7668\n",
      "Epoch [20], val_loss: 0.6005, val_acc: 0.7817\n",
      "Epoch [21], val_loss: 0.5936, val_acc: 0.7836\n",
      "Epoch [22], val_loss: 0.5818, val_acc: 0.7906\n",
      "Epoch [23], val_loss: 0.5783, val_acc: 0.7862\n",
      "Epoch [24], val_loss: 0.5491, val_acc: 0.8124\n",
      "Epoch [25], val_loss: 0.5791, val_acc: 0.7917\n",
      "Epoch [26], val_loss: 0.5518, val_acc: 0.8031\n",
      "Epoch [27], val_loss: 0.5976, val_acc: 0.7765\n",
      "Epoch [28], val_loss: 0.5674, val_acc: 0.7946\n",
      "Epoch [29], val_loss: 0.5628, val_acc: 0.7950\n",
      "Epoch [30], val_loss: 0.5289, val_acc: 0.8031\n",
      "Epoch [31], val_loss: 0.5397, val_acc: 0.8075\n",
      "Epoch [32], val_loss: 0.5263, val_acc: 0.8120\n",
      "Epoch [33], val_loss: 0.5452, val_acc: 0.8088\n",
      "Epoch [34], val_loss: 0.5548, val_acc: 0.8071\n",
      "Epoch [35], val_loss: 0.5646, val_acc: 0.7983\n",
      "Epoch [36], val_loss: 0.5448, val_acc: 0.7990\n",
      "Epoch [37], val_loss: 0.5210, val_acc: 0.8140\n",
      "Epoch [38], val_loss: 0.5019, val_acc: 0.8269\n",
      "Epoch [39], val_loss: 0.5537, val_acc: 0.8120\n",
      "Epoch [40], val_loss: 0.5335, val_acc: 0.8180\n",
      "Epoch [41], val_loss: 0.5565, val_acc: 0.8071\n",
      "Epoch [42], val_loss: 0.5307, val_acc: 0.8084\n",
      "Epoch [43], val_loss: 0.5247, val_acc: 0.8233\n",
      "Epoch [44], val_loss: 0.5364, val_acc: 0.8151\n",
      "Epoch [45], val_loss: 0.5280, val_acc: 0.8156\n",
      "Epoch [46], val_loss: 0.5529, val_acc: 0.8075\n",
      "Epoch [47], val_loss: 0.5294, val_acc: 0.8204\n",
      "Epoch [48], val_loss: 0.5435, val_acc: 0.8200\n",
      "Epoch [49], val_loss: 0.5928, val_acc: 0.8084\n",
      "Epoch [50], val_loss: 0.4987, val_acc: 0.8242\n",
      "Epoch [51], val_loss: 0.5051, val_acc: 0.8249\n",
      "Epoch [52], val_loss: 0.5401, val_acc: 0.8155\n",
      "Epoch [53], val_loss: 0.5422, val_acc: 0.8145\n",
      "Epoch [54], val_loss: 0.5254, val_acc: 0.8315\n",
      "Epoch [55], val_loss: 0.5493, val_acc: 0.8031\n",
      "Epoch [56], val_loss: 0.5401, val_acc: 0.8184\n",
      "Epoch [57], val_loss: 0.5292, val_acc: 0.8237\n",
      "Epoch [58], val_loss: 0.5564, val_acc: 0.8164\n",
      "Epoch [59], val_loss: 0.6043, val_acc: 0.8108\n",
      "Epoch [60], val_loss: 0.5514, val_acc: 0.8248\n",
      "Epoch [61], val_loss: 0.5376, val_acc: 0.8346\n",
      "Epoch [62], val_loss: 0.5181, val_acc: 0.8354\n",
      "Epoch [63], val_loss: 0.5502, val_acc: 0.8168\n",
      "Epoch [64], val_loss: 0.5535, val_acc: 0.8297\n",
      "Epoch [65], val_loss: 0.5228, val_acc: 0.8249\n",
      "Epoch [66], val_loss: 0.5332, val_acc: 0.8241\n",
      "Epoch [67], val_loss: 0.5685, val_acc: 0.8249\n",
      "Epoch [68], val_loss: 0.5027, val_acc: 0.8362\n",
      "Epoch [69], val_loss: 0.5481, val_acc: 0.8204\n",
      "Epoch [70], val_loss: 0.5369, val_acc: 0.8289\n",
      "Epoch [71], val_loss: 0.5658, val_acc: 0.8325\n",
      "Epoch [72], val_loss: 0.5727, val_acc: 0.8100\n",
      "Epoch [73], val_loss: 0.5498, val_acc: 0.8156\n",
      "Epoch [74], val_loss: 0.5609, val_acc: 0.8164\n",
      "Epoch [75], val_loss: 0.5492, val_acc: 0.8290\n",
      "Epoch [76], val_loss: 0.5795, val_acc: 0.8253\n",
      "Epoch [77], val_loss: 0.5341, val_acc: 0.8273\n",
      "Epoch [78], val_loss: 0.5270, val_acc: 0.8366\n",
      "Epoch [79], val_loss: 0.5836, val_acc: 0.8273\n",
      "Epoch [80], val_loss: 0.5274, val_acc: 0.8325\n",
      "Epoch [81], val_loss: 0.6031, val_acc: 0.8176\n",
      "Epoch [82], val_loss: 0.5410, val_acc: 0.8362\n",
      "Epoch [83], val_loss: 0.5340, val_acc: 0.8320\n",
      "Epoch [84], val_loss: 0.5467, val_acc: 0.8350\n",
      "Epoch [85], val_loss: 0.5563, val_acc: 0.8325\n",
      "Epoch [86], val_loss: 0.5210, val_acc: 0.8397\n",
      "Epoch [87], val_loss: 0.5587, val_acc: 0.8265\n",
      "Epoch [88], val_loss: 0.5657, val_acc: 0.8132\n",
      "Epoch [89], val_loss: 0.5541, val_acc: 0.8273\n",
      "Epoch [90], val_loss: 0.5703, val_acc: 0.8261\n",
      "Epoch [91], val_loss: 0.5267, val_acc: 0.8336\n",
      "Epoch [92], val_loss: 0.5959, val_acc: 0.8297\n",
      "Epoch [93], val_loss: 0.5732, val_acc: 0.8233\n",
      "Epoch [94], val_loss: 0.5923, val_acc: 0.8269\n",
      "Epoch [95], val_loss: 0.5466, val_acc: 0.8382\n",
      "Epoch [96], val_loss: 0.5668, val_acc: 0.8386\n",
      "Epoch [97], val_loss: 0.5642, val_acc: 0.8170\n",
      "Epoch [98], val_loss: 0.5447, val_acc: 0.8394\n",
      "Epoch [99], val_loss: 0.5557, val_acc: 0.8366\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(100, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b42bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.5332, val_acc: 0.7962\n",
      "Epoch [1], val_loss: 0.4891, val_acc: 0.8221\n",
      "Epoch [2], val_loss: 0.4592, val_acc: 0.8238\n",
      "Epoch [3], val_loss: 0.5080, val_acc: 0.8144\n",
      "Epoch [4], val_loss: 0.4624, val_acc: 0.8319\n",
      "Epoch [5], val_loss: 0.4364, val_acc: 0.8347\n",
      "Epoch [6], val_loss: 0.4645, val_acc: 0.8291\n",
      "Epoch [7], val_loss: 0.4730, val_acc: 0.8193\n",
      "Epoch [8], val_loss: 0.4759, val_acc: 0.8293\n",
      "Epoch [9], val_loss: 0.4567, val_acc: 0.8375\n",
      "Epoch [10], val_loss: 0.4641, val_acc: 0.8403\n",
      "Epoch [11], val_loss: 0.4743, val_acc: 0.8305\n",
      "Epoch [12], val_loss: 0.4606, val_acc: 0.8324\n",
      "Epoch [13], val_loss: 0.4631, val_acc: 0.8415\n",
      "Epoch [14], val_loss: 0.4790, val_acc: 0.8297\n",
      "Epoch [15], val_loss: 0.4841, val_acc: 0.8344\n",
      "Epoch [16], val_loss: 0.4403, val_acc: 0.8421\n",
      "Epoch [17], val_loss: 0.4599, val_acc: 0.8430\n",
      "Epoch [18], val_loss: 0.4667, val_acc: 0.8336\n",
      "Epoch [19], val_loss: 0.4456, val_acc: 0.8466\n",
      "Epoch [20], val_loss: 0.4663, val_acc: 0.8359\n",
      "Epoch [21], val_loss: 0.4646, val_acc: 0.8403\n",
      "Epoch [22], val_loss: 0.4721, val_acc: 0.8430\n",
      "Epoch [23], val_loss: 0.4694, val_acc: 0.8393\n",
      "Epoch [24], val_loss: 0.4832, val_acc: 0.8424\n",
      "Epoch [25], val_loss: 0.4790, val_acc: 0.8394\n",
      "Epoch [26], val_loss: 0.4710, val_acc: 0.8487\n",
      "Epoch [27], val_loss: 0.4965, val_acc: 0.8419\n",
      "Epoch [28], val_loss: 0.5278, val_acc: 0.8416\n",
      "Epoch [29], val_loss: 0.4692, val_acc: 0.8352\n",
      "Epoch [30], val_loss: 0.5044, val_acc: 0.8418\n",
      "Epoch [31], val_loss: 0.5177, val_acc: 0.8333\n",
      "Epoch [32], val_loss: 0.4853, val_acc: 0.8458\n",
      "Epoch [33], val_loss: 0.5146, val_acc: 0.8374\n",
      "Epoch [34], val_loss: 0.5067, val_acc: 0.8416\n",
      "Epoch [35], val_loss: 0.4878, val_acc: 0.8480\n",
      "Epoch [36], val_loss: 0.5172, val_acc: 0.8349\n",
      "Epoch [37], val_loss: 0.4864, val_acc: 0.8533\n",
      "Epoch [38], val_loss: 0.4799, val_acc: 0.8596\n",
      "Epoch [39], val_loss: 0.5607, val_acc: 0.8386\n",
      "Epoch [40], val_loss: 0.5503, val_acc: 0.8393\n",
      "Epoch [41], val_loss: 0.4852, val_acc: 0.8468\n",
      "Epoch [42], val_loss: 0.5185, val_acc: 0.8481\n",
      "Epoch [43], val_loss: 0.5339, val_acc: 0.8521\n",
      "Epoch [44], val_loss: 0.5087, val_acc: 0.8478\n",
      "Epoch [45], val_loss: 0.4735, val_acc: 0.8591\n",
      "Epoch [46], val_loss: 0.5345, val_acc: 0.8474\n",
      "Epoch [47], val_loss: 0.5083, val_acc: 0.8490\n",
      "Epoch [48], val_loss: 0.4973, val_acc: 0.8612\n",
      "Epoch [49], val_loss: 0.5900, val_acc: 0.8327\n",
      "Epoch [50], val_loss: 0.5082, val_acc: 0.8452\n",
      "Epoch [51], val_loss: 0.5330, val_acc: 0.8355\n",
      "Epoch [52], val_loss: 0.5446, val_acc: 0.8481\n",
      "Epoch [53], val_loss: 0.5074, val_acc: 0.8525\n",
      "Epoch [54], val_loss: 0.5382, val_acc: 0.8493\n",
      "Epoch [55], val_loss: 0.4994, val_acc: 0.8477\n",
      "Epoch [56], val_loss: 0.5380, val_acc: 0.8415\n",
      "Epoch [57], val_loss: 0.5433, val_acc: 0.8468\n",
      "Epoch [58], val_loss: 0.5501, val_acc: 0.8480\n",
      "Epoch [59], val_loss: 0.5311, val_acc: 0.8468\n",
      "Epoch [60], val_loss: 0.5330, val_acc: 0.8456\n",
      "Epoch [61], val_loss: 0.5413, val_acc: 0.8502\n",
      "Epoch [62], val_loss: 0.5489, val_acc: 0.8518\n",
      "Epoch [63], val_loss: 0.5450, val_acc: 0.8411\n",
      "Epoch [64], val_loss: 0.5131, val_acc: 0.8487\n",
      "Epoch [65], val_loss: 0.5372, val_acc: 0.8427\n",
      "Epoch [66], val_loss: 0.5284, val_acc: 0.8430\n",
      "Epoch [67], val_loss: 0.5813, val_acc: 0.8408\n",
      "Epoch [68], val_loss: 0.5779, val_acc: 0.8433\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history2 \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 12\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m## Training Phas\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 12\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[62], line 55\u001b[0m, in \u001b[0;36mMnistModel.training_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m     54\u001b[0m     images, goals, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 55\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m## Generate predictions\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(out, labels) \u001b[38;5;66;03m## Calculate the loss\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(loss)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[62], line 29\u001b[0m, in \u001b[0;36mMnistModel.forward\u001b[0;34m(self, x, g)\u001b[0m\n\u001b[1;32m     27\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(out)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# print(out.shape)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(out)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(out.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history2 = fit(100, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8edf808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.5524, val_acc: 0.8211\n",
      "Epoch [1], val_loss: 0.5431, val_acc: 0.8358\n",
      "Epoch [2], val_loss: 0.5241, val_acc: 0.8265\n",
      "Epoch [3], val_loss: 0.5704, val_acc: 0.8128\n",
      "Epoch [4], val_loss: 0.5372, val_acc: 0.8248\n",
      "Epoch [5], val_loss: 0.5274, val_acc: 0.8320\n",
      "Epoch [6], val_loss: 0.5204, val_acc: 0.8358\n",
      "Epoch [7], val_loss: 0.5584, val_acc: 0.8135\n",
      "Epoch [8], val_loss: 0.5756, val_acc: 0.8217\n",
      "Epoch [9], val_loss: 0.5322, val_acc: 0.8289\n",
      "Epoch [10], val_loss: 0.5167, val_acc: 0.8300\n",
      "Epoch [11], val_loss: 0.5262, val_acc: 0.8325\n",
      "Epoch [12], val_loss: 0.5360, val_acc: 0.8236\n",
      "Epoch [13], val_loss: 0.5598, val_acc: 0.8241\n",
      "Epoch [14], val_loss: 0.5486, val_acc: 0.8236\n",
      "Epoch [15], val_loss: 0.5524, val_acc: 0.8219\n",
      "Epoch [16], val_loss: 0.5428, val_acc: 0.8232\n",
      "Epoch [17], val_loss: 0.5510, val_acc: 0.8245\n",
      "Epoch [18], val_loss: 0.5410, val_acc: 0.8273\n",
      "Epoch [19], val_loss: 0.5330, val_acc: 0.8334\n",
      "Epoch [20], val_loss: 0.5482, val_acc: 0.8243\n",
      "Epoch [21], val_loss: 0.5256, val_acc: 0.8296\n",
      "Epoch [22], val_loss: 0.5445, val_acc: 0.8196\n",
      "Epoch [23], val_loss: 0.5137, val_acc: 0.8252\n",
      "Epoch [24], val_loss: 0.5466, val_acc: 0.8272\n",
      "Epoch [25], val_loss: 0.5705, val_acc: 0.8217\n",
      "Epoch [26], val_loss: 0.5794, val_acc: 0.8099\n",
      "Epoch [27], val_loss: 0.5759, val_acc: 0.8241\n",
      "Epoch [28], val_loss: 0.5800, val_acc: 0.8253\n",
      "Epoch [29], val_loss: 0.5697, val_acc: 0.8213\n",
      "Epoch [30], val_loss: 0.5629, val_acc: 0.8248\n",
      "Epoch [31], val_loss: 0.5474, val_acc: 0.8300\n",
      "Epoch [32], val_loss: 0.6022, val_acc: 0.8113\n",
      "Epoch [33], val_loss: 0.5502, val_acc: 0.8300\n",
      "Epoch [34], val_loss: 0.5584, val_acc: 0.8336\n",
      "Epoch [35], val_loss: 0.5733, val_acc: 0.8115\n",
      "Epoch [36], val_loss: 0.5642, val_acc: 0.8260\n",
      "Epoch [37], val_loss: 0.5811, val_acc: 0.8164\n",
      "Epoch [38], val_loss: 0.5578, val_acc: 0.8312\n",
      "Epoch [39], val_loss: 0.5548, val_acc: 0.8320\n",
      "Epoch [40], val_loss: 0.6212, val_acc: 0.8213\n",
      "Epoch [41], val_loss: 0.5720, val_acc: 0.8317\n",
      "Epoch [42], val_loss: 0.5802, val_acc: 0.8253\n",
      "Epoch [43], val_loss: 0.5631, val_acc: 0.8183\n",
      "Epoch [44], val_loss: 0.5801, val_acc: 0.8296\n",
      "Epoch [45], val_loss: 0.5740, val_acc: 0.8232\n",
      "Epoch [46], val_loss: 0.5749, val_acc: 0.8268\n",
      "Epoch [47], val_loss: 0.5892, val_acc: 0.8200\n",
      "Epoch [48], val_loss: 0.5642, val_acc: 0.8292\n",
      "Epoch [49], val_loss: 0.5588, val_acc: 0.8269\n",
      "Epoch [50], val_loss: 0.5392, val_acc: 0.8342\n",
      "Epoch [51], val_loss: 0.5740, val_acc: 0.8289\n",
      "Epoch [52], val_loss: 0.5511, val_acc: 0.8338\n",
      "Epoch [53], val_loss: 0.5468, val_acc: 0.8342\n",
      "Epoch [54], val_loss: 0.5830, val_acc: 0.8237\n",
      "Epoch [55], val_loss: 0.5557, val_acc: 0.8358\n",
      "Epoch [56], val_loss: 0.5934, val_acc: 0.8084\n",
      "Epoch [57], val_loss: 0.5390, val_acc: 0.8309\n",
      "Epoch [58], val_loss: 0.5443, val_acc: 0.8381\n",
      "Epoch [59], val_loss: 0.5808, val_acc: 0.8224\n",
      "Epoch [60], val_loss: 0.5604, val_acc: 0.8316\n",
      "Epoch [61], val_loss: 0.5532, val_acc: 0.8280\n",
      "Epoch [62], val_loss: 0.6136, val_acc: 0.8233\n",
      "Epoch [63], val_loss: 0.6106, val_acc: 0.8245\n",
      "Epoch [64], val_loss: 0.5625, val_acc: 0.8285\n",
      "Epoch [65], val_loss: 0.6044, val_acc: 0.8233\n",
      "Epoch [66], val_loss: 0.5740, val_acc: 0.8265\n",
      "Epoch [67], val_loss: 0.5560, val_acc: 0.8346\n",
      "Epoch [68], val_loss: 0.5594, val_acc: 0.8256\n",
      "Epoch [69], val_loss: 0.6051, val_acc: 0.8180\n",
      "Epoch [70], val_loss: 0.5649, val_acc: 0.8338\n",
      "Epoch [71], val_loss: 0.5853, val_acc: 0.8285\n",
      "Epoch [72], val_loss: 0.6155, val_acc: 0.8188\n",
      "Epoch [73], val_loss: 0.6060, val_acc: 0.8195\n",
      "Epoch [74], val_loss: 0.5657, val_acc: 0.8241\n",
      "Epoch [75], val_loss: 0.5441, val_acc: 0.8426\n",
      "Epoch [76], val_loss: 0.5721, val_acc: 0.8233\n",
      "Epoch [77], val_loss: 0.5854, val_acc: 0.8253\n",
      "Epoch [78], val_loss: 0.5813, val_acc: 0.8276\n",
      "Epoch [79], val_loss: 0.6071, val_acc: 0.8204\n",
      "Epoch [80], val_loss: 0.6009, val_acc: 0.8184\n",
      "Epoch [81], val_loss: 0.5918, val_acc: 0.8191\n",
      "Epoch [82], val_loss: 0.5917, val_acc: 0.8226\n",
      "Epoch [83], val_loss: 0.5820, val_acc: 0.8340\n",
      "Epoch [84], val_loss: 0.5876, val_acc: 0.8280\n",
      "Epoch [85], val_loss: 0.5935, val_acc: 0.8285\n",
      "Epoch [86], val_loss: 0.5676, val_acc: 0.8293\n",
      "Epoch [87], val_loss: 0.6036, val_acc: 0.8253\n",
      "Epoch [88], val_loss: 0.5843, val_acc: 0.8296\n",
      "Epoch [89], val_loss: 0.5950, val_acc: 0.8293\n",
      "Epoch [90], val_loss: 0.6062, val_acc: 0.8315\n",
      "Epoch [91], val_loss: 0.5718, val_acc: 0.8309\n",
      "Epoch [92], val_loss: 0.5786, val_acc: 0.8305\n",
      "Epoch [93], val_loss: 0.6311, val_acc: 0.8176\n",
      "Epoch [94], val_loss: 0.5949, val_acc: 0.8382\n",
      "Epoch [95], val_loss: 0.6177, val_acc: 0.8160\n",
      "Epoch [96], val_loss: 0.5887, val_acc: 0.8323\n",
      "Epoch [97], val_loss: 0.5996, val_acc: 0.8191\n",
      "Epoch [98], val_loss: 0.6197, val_acc: 0.8188\n",
      "Epoch [99], val_loss: 0.6027, val_acc: 0.8237\n"
     ]
    }
   ],
   "source": [
    "history3 = fit(100, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719562d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113113c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "deb8c5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Replace these values with your result\n",
    "history = [result0] + history1# + history2 + history3# + history4\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy Vs. No. of epochs')\n",
    "plt.savefig('/home/alex/Documents/NN_path_planning/nn/model/plot_Accuracy Vs. No. of epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "98761a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/home/alex/Documents/NN_path_planning/nn/model/model_v3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2a8da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = torch.load('/home/alex/Documents/NN_path_planning/nn/model/model_v3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5173a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501666/1757807647.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  action = F.softmax(output).detach().numpy().argmax()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_1.forward(custom_dataset[3000][0])\n",
    "# _, pred = torch.max(output)\n",
    "action = F.softmax(output).detach().numpy().argmax()\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8230df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67286ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8e2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
